{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GEOG5990M Portfolio Assignment 2\n",
        "\n",
        "Student ID number: 201682556\n"
      ],
      "metadata": {
        "id": "lr9-ZtlnjU6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "In my final project I will be assessing whether the number of burglaries within key city’s is correlated to the distance of the property to what is considered a primary road, for example a motorway junction. The idea being investigated is that burglars are more likely to target properties and areas that have excellent highway connections to a primary road allowing them to both get away quickly as well as disguise themselves amongst a large amount of traffic making it less likely the police will be able to identify their vehicle in a sufficient time. The output areas I have chosen for this investigation are prominent cities in the North of England; Leeds, Bradford, Sheffield, and Hull.\n",
        "\n"
      ],
      "metadata": {
        "id": "IZu1myWOjbCG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYsd-DOIjOHE"
      },
      "outputs": [],
      "source": [
        "#This file was made in google colab\n",
        "\n",
        "#first use pip for contextily and geoplot packages\n",
        "!pip install contextily\n",
        "!pip install geoplot\n",
        "\n",
        "#Import the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyproj\n",
        "import contextily as ctx\n",
        "import seaborn as sns\n",
        "#create points from excel\n",
        "import fiona\n",
        "#from collections import OrderedDict\n",
        "\n",
        "import geoplot as gplt\n",
        "import geoplot.crs as gcrs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing:\n",
        "\n",
        "The Census data was taken from a bulk download of 2021 from the NOMIS webpage (Nomis, 2021). The chosen category’s which would have the most influence was TS006: Population density, TS017: Household size and TS050 number of bedrooms. As each category is its own excel sheet, I elected to merge all of them together before preprocessing using python. I also formatted the household size into a simple two columns; properties with up to three people and properties more than 3 people, reducing from the original eight columns.\n",
        "\n",
        "The Crime data was downloaded using a custom data download widget, specifying February 2023 – February 2024, this was the latest data available and I wanted to analyse the data over a one-year period (data.police, no date). This download was separated by month so I combined all twelve sheets into one spreadsheet. Originally, I was going to convert the excel file into a geo-frame within python, however I was not able to read the geo-frame in further command lines so I opted to add the excel file to QGIS and create the geometry, saving as a shapefile. Since I was creating a new shapefile, I also converted the results into British National Grid (BNG) from latitude longitude.\n",
        "\n",
        "I downloaded the road network data from Digimaps using the BNG tile function, SE, SK, and TA (digimap, 2023). As each of these contained 2 separate shapefiles for network and nodes, I merged all the Road_Link shapefiles together however this was a large file at 500MB so I decided to condense this further before processing in python by selecting all roads that intersect inside or out, the target cities. In addition to the road data, I also created an ad-hoc standalone shapefile containing the starting points of all the roads where primary equals true i.e. Motorways, major trunk roads or arterial roads.\n",
        "\n",
        "Output areas (polygons) were downloaded from Geoportal (Geoportal Statistics, 2023), I went with the Dec 2021 download to match as close as possible the recorded census data as the LSOA codes generally has slight variation between years. I filtered this output using the website interactive mapping tool and drew a box around my area of interest. This allowed me to download a much smaller area than the original entire country’s worth of areas, I also manually edited this in QGIS to further remove extraneous polygons that were not in the study areas making the large file size as small as possible.\n"
      ],
      "metadata": {
        "id": "YucUyk_jl_cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data-preprocessing\n",
        "\n",
        "#Import shapefiles\n",
        "\n",
        "## the dbf/shp may take several minutes to upload if using google colab\n",
        "\n",
        "#Excel\n",
        "census = pd.read_excel(\"census_merged.xlsx\")\n",
        "\n",
        "#crime Points\n",
        "crimes_merged = gpd.read_file(\"crimes_merged.shp\")\n",
        "\n",
        "#road Points\n",
        "road_start_points = gpd.read_file(\"primary_roads_start_points.shp\")\n",
        "\n",
        "#Lines\n",
        "roads = gpd.read_file(\"major_roads.shp\")\n",
        "#Polygons\n",
        "LSOA = gpd.read_file(\"Output_Areas_Dec_2021_v2.shp\")\n",
        "\n",
        "# Old excel file for crimes\n",
        "#crimes = pd.read_excel(\"crimes_merged.xlsx\")"
      ],
      "metadata": {
        "id": "XV2b1uGUmB7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSOA.explore()"
      ],
      "metadata": {
        "id": "10ECAAi8r-xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSOA.dtypes"
      ],
      "metadata": {
        "id": "B_26rAkawFN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roads.dtypes"
      ],
      "metadata": {
        "id": "NnQEbuF4YcAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roads.head()"
      ],
      "metadata": {
        "id": "M4Rsi6ytwFHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I clean the Output areas to only include the chosen city’s using a string contains function to find key words and text as the output areas download does not have a standalone column with city names by default. Using the explore function you can visualise the area of my investigation clearly, this file with be used as an important template for other datasets later. Checking the coordinate systems are all the same.\n"
      ],
      "metadata": {
        "id": "-b5670RUFlxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter LSOA to target areas within the City Limits\n",
        "#Selecting rows IF contains city\n",
        "\n",
        "#Only returns a maximum of two cities to display\n",
        "#lsoa_cleaned = LSOA.loc[LSOA[\"lsoa11nm\"].str.contains(\"Leeds | Bradford | Hull | Sheffield\")]\n",
        "\n",
        "# Use long code instead of concatenating into one bracket to fix above issue.\n",
        "lsoa_cleaned = LSOA.loc[LSOA[\"LSOA21NM\"].str.contains(\"Leeds\") | (LSOA[\"LSOA21NM\"].str.contains(\"Bradford\") | (LSOA[\"LSOA21NM\"].str.contains(\"Hull\") | (LSOA[\"LSOA21NM\"].str.contains(\"Sheffield\") )))]\n",
        "\n",
        "lsoa_cleaned.explore(width=\"80%\", height=\"60%\")"
      ],
      "metadata": {
        "id": "vxr46LYiwE9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clip all roads by poylgons then filter to make primary"
      ],
      "metadata": {
        "id": "wnJXlrJCPT2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make sure CRS are the same\n",
        "print('lsoa_cleaned.crs:', lsoa_cleaned.crs)\n",
        "print('roads.crs:', roads.crs)\n",
        "print('crimes.crs:', roads.crs)"
      ],
      "metadata": {
        "id": "O5KGagqTPpYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coord systems coversion (no longer needed)\n",
        "#lsoa_cleaned = lsoa_cleaned.to_crs(epsg=27700) #BNG\n",
        "\n",
        "#make sure dataframes CRS are the same\n",
        "#print('lsoa_cleaned.crs:', lsoa_cleaned.crs)\n",
        "#print('roads.crs:', roads.crs)"
      ],
      "metadata": {
        "id": "LkXfEzlHPgab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create a dissolved polygon of the city’s and then clipped the road links shapefile using this polygon to only use the relevant roads located in and adjoining the cities. I chose to include the adjoining roads as well as there may be instances where roads are on the boundary of the city but not in which would alter the estimated road distance quite drastically in some cases. Creating a dissolved polygon works better than 6,000 individual ones as some roads may be clipped in unexpected ways, this also helps with the speed and optimisation of the python file."
      ],
      "metadata": {
        "id": "IwsxTk81Fre3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dissolve poylgons\n",
        "city_polygons = lsoa_cleaned.dissolve()\n",
        "city_polygons.explore(width=\"80%\", height=\"60%\")\n",
        "\n",
        "city_polygons.plot()\n",
        "print('city_polygons.crs:', city_polygons.crs)"
      ],
      "metadata": {
        "id": "XtqjcLsiQECQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clip Road network by City_Dissolved\n",
        "\n",
        "#Specify lines, and mask to clip by\n",
        "roads_clipped = gpd.clip(roads, city_polygons)\n",
        "\n",
        "roads_clipped.explore(width=\"80%\", height=\"60%\")"
      ],
      "metadata": {
        "id": "0_DcLdBjQOQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roads_clipped.head()"
      ],
      "metadata": {
        "id": "cP4UandGry8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Copy the road network and make an ONLY Primary Roads layer\n",
        "#filter to just motorways and primary A roads\n",
        "primary_roads = roads_clipped[roads_clipped[\"class\"].str.contains(\"Motorway\") | (roads_clipped[\"class\"].str.contains(\"A Road\") & (roads_clipped[\"primary\"] == ('true')))]\n",
        "\n",
        "#primary_roads = roads_clipped[roads_clipped[\"class\"].str.contains(\"Motorway\") & (roads_clipped[\"primary\"] == ('true') | (roads_clipped[\"class\"].str.contains(\"A Road\") & (roads_clipped[\"primary\"] == ('true'))))]\n",
        "\n",
        "#Keeping certain columns removes the geometry field, so drop specific columns instead\n",
        "primary_roads = primary_roads.drop(['path', 'layer','loop','startNode','endNode','fictitious','identifier','name1','name1_lang','name2','name2_lang','nameTOID','numberTOID','structure'], axis=1, )\n",
        "\n",
        "primary_roads.explore(width=\"80%\", height=\"60%\")"
      ],
      "metadata": {
        "id": "PjtKM6zP0SZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My original plan was to upload the crimes excel sheet and convert into a geodata frame using the Fiona package however I experienced problems with the folium map section (Data Ninjas, 2021). So, I opted instead to create the shapefile as above."
      ],
      "metadata": {
        "id": "oCSW4vE7qKzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check dtypes\n",
        "#crimes.head()\n",
        "#crimes.dtypes\n",
        "\n",
        "# Create coordiantes column, specify as a list and concatinate the Lat, Long\n",
        "#crimes['coordinates'] = crimes[['Longitude','Latitude']].values.tolist()\n",
        "#crimes.head()\n",
        "\n",
        "#from shapely.geometry import Point\n",
        "# Add point infront of coords list\n",
        "#crimes['coordinates'] = crimes['coordinates'].apply(Point)\n",
        "#crimes.head()\n",
        "\n",
        "#find dataframe type\n",
        "#type(crimes)\n",
        "\n",
        "# use column \"coords\" as geometry, check dataframe type\n",
        "#crime_points = gpd.GeoDataFrame(crimes, geometry = 'coordinates')\n",
        "#type(crime_points)\n",
        "\n",
        "#crime_points.plot()\n",
        "#crime_points.explore()\n",
        "\n",
        "#crime_points = crime_points.set_crs('epsg:4326')\n",
        "#crime_points.crs\n",
        "#crime_points = crime_points.to_crs('epsg:27700')\n",
        "#crime_points.crs\n",
        "\n",
        "#crime_points.to_file('export.shp')\n",
        "#needd to export firrst??? gdf\n",
        "#crimes_plotted = gpd.read_file(\"export.shp\")\n",
        "\n",
        "#crimes_plotted.explore()\n",
        "\n",
        "#TypeError: 'NoneType' object is not subscriptable\n",
        "#<folium.folium.Map at 0x7a25554564a0>"
      ],
      "metadata": {
        "id": "1GnNUwUdo-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crimes_merged.head()"
      ],
      "metadata": {
        "id": "xxiqB-pNsIRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clip burglary points to just Cities of interest, this also remove any null geometry\n",
        "crimes_clipped = gpd.clip(crimes_merged, city_polygons)\n",
        "\n",
        "# Locate only Burglary Data\n",
        "burglary = crimes_clipped.loc[crimes_clipped['Crime_type']=='Burglary']\n",
        "\n",
        "burglary.explore(width=\"80%\", height=\"60%\")"
      ],
      "metadata": {
        "id": "TU4cO_EL-ykM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was also going to calculate the distance between points along a network to gain a true distance from burglary to primary road but due to a problem of conflicting tool instructions and package version instructions I could not get the get_nearest_node command to work (automating-gis-processes, 2017). To get around this I chose to use the Euclidian distance (do-me, 2023), although this would not be a true account it could still be used as a reasonable estimate of distance for this use case.\n",
        "\n",
        "Utilising the spatial join command against burglary points and the primary road start points I created my new data frame, using a maximum distance tolerance of 2000m to reduce any outlier distances as most of the city would be covered within 2000m. I also calculated some additional statistics using this distance information to join onto the LSOA data frame using the group-by and aggregate functions to summarise the count of burglaries and the average distance to the primary road per output area."
      ],
      "metadata": {
        "id": "jPpI2YOs1k5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "road_start_points.head()"
      ],
      "metadata": {
        "id": "vYxz1SJZw091"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find nearest primary road point from burglary point\n",
        "crime_dist = gpd.sjoin_nearest(burglary, road_start_points, how='inner', max_distance = 2000, distance_col=\"distance\", lsuffix=\"left\", rsuffix=\"right\")"
      ],
      "metadata": {
        "id": "rBUcsPgp5BPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crime_dist.info()"
      ],
      "metadata": {
        "id": "rs-d2U1i1lHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only keep LSOA and distance columns\n",
        "crime_dist = crime_dist[['LSOA_name', 'distance']]\n",
        "#add copied column of distance for avg distance calculation\n",
        "crime_dist['avg_dist'] = crime_dist['distance']\n",
        "\n",
        "# Create new df for count of crimes in LSOA\n",
        "crime_count = crime_dist.groupby('LSOA_name').count().reset_index().rename(columns={'distance':'count_of_burg'})\n",
        "# Create group column for avergae distance\n",
        "crime_count1 = crime_dist.groupby('LSOA_name').agg({'distance':'mean'}).reset_index().rename(columns={'distance':'avg_distance'})\n",
        "#Merge results together to form one reocrd per LSOA with count and avg.\n",
        "crime_graph = pd.merge(crime_count, crime_count1, how='inner', left_on='LSOA_name', right_on='LSOA_name')\n",
        "#Remove duplicate column\n",
        "crime_graph = crime_graph.drop(columns=['avg_dist'])\n",
        "\n",
        "crime_graph.head()"
      ],
      "metadata": {
        "id": "iUPBX8g_ytce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge LSOA_cleaned data onto crime count and avg ditance data\n",
        "crime_census = pd.merge(lsoa_cleaned, crime_graph, how='left', left_on='LSOA21NM', right_on='LSOA_name')\n",
        "# Merge the LSOA and crime data onto Census data\n",
        "crime_census = pd.merge(crime_census, census, how='left', left_on='LSOA21NM', right_on='geography')\n",
        "\n",
        "crime_census.explore(width=\"80%\", height=\"60%\")"
      ],
      "metadata": {
        "id": "SFyaD-R730e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a centroid layer of LSOAs\n",
        "# copy GeoDataFrame\n",
        "#lsoa_centroid = crime_census.copy()\n",
        "# change geometry to centroid of LSOA\n",
        "#lsoa_centroid['geometry'] = lsoa_centroid['geometry'].centroid\n",
        "#lsoa_centroid.head()"
      ],
      "metadata": {
        "id": "8qFwSr304tYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lsoa_cleaned = LSOA.loc[LSOA[\"LSOA21NM\"].str.contains(\"Leeds | Bradford | Hull | Sheffield\")]  #already have????"
      ],
      "metadata": {
        "id": "9ftb9bSGjAg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the last part of data processing, I split the data frames into their respective city limits Leeds, Sheffield, Bradford. Hull was left out of the final visualisation as there were no burglary points visualised in the Hull area."
      ],
      "metadata": {
        "id": "ZF222iTjGvax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crime_census.head()"
      ],
      "metadata": {
        "id": "Ezat61erlkFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter LSOA data and make new dataframe for each city, to aid in map image scaling\n",
        "spatial_leeds = crime_census.loc[crime_census[\"LSOA21NM\"].str.contains(\"Leeds\")]\n",
        "spatial_bradford = crime_census.loc[crime_census[\"LSOA21NM\"].str.contains(\"Bradford\")]\n",
        "spatial_sheffield = crime_census.loc[crime_census[\"LSOA21NM\"].str.contains(\"Sheffield\")]\n",
        "\n",
        "# Clip Primary Roads to make new dfs for each city\n",
        "primary_leeds = gpd.clip(primary_roads, spatial_leeds)\n",
        "primary_bradford = gpd.clip(primary_roads, spatial_bradford)\n",
        "primary_sheffield = gpd.clip(primary_roads, spatial_sheffield)"
      ],
      "metadata": {
        "id": "ltFk5YMIkVmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation:\n",
        "\n",
        "Using Spearman’s correlation, I found that the average distance has an overall weak relationship to the number of burglaries but a moderate relationship between number of burglary and both one- and two-bedroom accommodation. These are found on the outskirts of the city, however there are also some accommodations within. For this visual I used a mask to cover off the other half of the data to tidy up the map. I used the RdBu colour palette as using colour brewer as a reference of different possible palettes for my graphs and this one is a colourblind friendly choice and is best used as a diverging colour scheme (Aptech, 2024)."
      ],
      "metadata": {
        "id": "YwlA_52YI_-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Spearman's rank correlation\n",
        "spearmans = crime_census[['count_of_burg',\n",
        "       'avg_distance',\n",
        "       'Population Density: km2',\n",
        "       'Household size: <3 people in household',\n",
        "      'Household size: +3 people in household','Number of bedrooms: 1 bedroom','Number of bedrooms: 2 bedrooms',\n",
        "      'Number of bedrooms: 3 bedrooms','Number of bedrooms: 4 or more bedrooms']].corr(method = 'spearman')\n",
        "spearmans"
      ],
      "metadata": {
        "id": "Pu7vG88yORQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define plot size\n",
        "fig,ax = plt.subplots(figsize=(8,8))\n",
        "\n",
        "# define mask to apply to upper right hand corner of the plot\n",
        "data_to_mask = np.triu(np.ones_like(spearmans))\n",
        "\n",
        "# plot a heatmap of the correlation dataframe\n",
        "sns.heatmap(spearmans,\n",
        "            # annotate so spearman's rank correlation values are displayed on the squares\n",
        "            annot=True,\n",
        "            # define colourmap\n",
        "            cmap='RdBu',\n",
        "            # define value of minimum colour on cbar\n",
        "            vmin=-1,\n",
        "            # define value of maximum colour on cbar\n",
        "            vmax=1,\n",
        "            # add the mask\n",
        "            mask=data_to_mask,\n",
        "            # add a label to the cbar\n",
        "            cbar_kws={'label': \"Spearman's Rank correlation\"},\n",
        "            # plot on the axis we defined\n",
        "            ax=ax)\n",
        "\n",
        "# Set axis labels\n",
        "ax.set(title =\"Correlation Census for Burglary's near Primary Roads\" );\n",
        "\n",
        "#for online google colab download\n",
        "from google.colab import files\n",
        "plt.savefig(\"Correlation Census for Burglary's near Primary Roads.png\")\n",
        "files.download(\"Correlation Census for Burglary's near Primary Roads.png\")"
      ],
      "metadata": {
        "id": "tviJeFZZPdi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(crime_dist, x=\"distance\")\n",
        "plt.xlabel(\"Distance from Primary Road (m)\")\n",
        "plt.ylabel(\"Count of Burglarys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qhDrwW9l9lal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my visuals I chose a green colour for the joint plot scatter graph, this was going to be blue but I though the contrast between the dark blue and light blue colours made it difficult to clearly see the results so I opted for a green instead, a single colour tone will not affect visually impaired users. Using the bar charts, you can see a cluster near the 250m mark which steadily decreases with greater distances from the primary roads.\n",
        "Better visualised by the hex plot graph it is far easier to spot clusters of significance in darker blue where there is lots of overlap of results, which was very difficult to identify on the previous graph. The correlation shows a larger concentration of burglary’s along the 250m mark which carries over to 500m and steadily declines from the 750m mark. I also renamed the axis labels to be more intuitive for the users who will be the Police force and crime analysts giving them a clear and easily read graph.\n"
      ],
      "metadata": {
        "id": "Im8od3mrG5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# joint plot, specify colour and marker type\n",
        "sns.jointplot(x='avg_distance',y='count_of_burg', color='green', kind ='scatter',data=crime_graph,\n",
        "            height=10, marker='*');\n",
        "# add label axis\n",
        "plt.xlabel(\"Average distance from Primary Road (m)\")\n",
        "plt.ylabel(\"Count of Burglarys per Output Area\")\n",
        "plt.title(\"LSOA Burglarys by Average Distance to Primary road\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bMWqZo_1-tEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a hex plot\n",
        "sns.jointplot(x='avg_distance',y='count_of_burg', kind ='hex',data=crime_graph);\n",
        "# add label axis\n",
        "plt.xlabel(\"Average distance from Primary Road (m)\")\n",
        "plt.ylabel(\"Count of Burglarys per Output Area\")\n",
        "plt.title(\"Output Area Burglary's by Average Distance to Primary road\", y=1.2, fontsize = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OK-GxDl3-s8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphs:\n",
        "\n",
        "For the final visual I plotted the spatial representation of burglary and added the primary road layer relative to the output areas allowing for easy identification of hotspots and clusters of data. This is so the police and crime analysts will instinctively be able to tell areas of focus against the road network their familiar with to reduce the crime rate. I used the ‘YlOrRd’ colour palette as this is both colour blind friendly (Aptech, 2024) and you can easily distinguish the different level of burglary rates by using the ‘temperature’ of the colour.\n",
        "\n",
        "On the maps, you can see a high concentration near the centre of Leeds which is completely encircled by primary roads and other clusters directly in between these prime roads. Lighter colours are seen farther from the prime roads. This description can be effectively applied to all the other maps as well.\n"
      ],
      "metadata": {
        "id": "C-ElW_zA5Zpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a figure with three subplots (maps)\n",
        "f,ax = plt.subplots(3,1, figsize=(36,24))\n",
        "\n",
        "# plot leeds in subplot 1 and leeds roads\n",
        "base1 = spatial_leeds.plot(ax=ax[0], column ='count_of_burg', cmap='YlOrRd', legend=True)\n",
        "primary_leeds.plot(ax=base1,color='red')\n",
        "\n",
        "# plot bradford in subplot 2 and bradford roads\n",
        "base2 = spatial_bradford.plot(ax=ax[1], column ='count_of_burg', cmap='YlOrRd', legend=True)\n",
        "primary_bradford.plot(ax=base2,color='red')\n",
        "\n",
        "# plot sheffield in subplot 3 and sheffield roads\n",
        "base3 = spatial_sheffield.plot(ax=ax[2], column ='count_of_burg', cmap='YlOrRd', legend=True)\n",
        "primary_sheffield.plot(ax=base3,color='red')\n",
        "\n",
        "# give subplot 1 title\n",
        "# Use ax[0] to speficy plots\n",
        "ax[0].set_title(\"Leeds Burglarys by LSOA 2023-2024\")\n",
        "# give subplot 2 title\n",
        "ax[1].set_title(\"Bradford Burglarys by LSOA 2023-2024\")\n",
        "# give subplot 3 title\n",
        "ax[2].set_title(\"Sheffield Burglarys by LSOA 2023-2024\")\n",
        "\n",
        "# make axis invisible\n",
        "ax[0].set_axis_off()\n",
        "ax[1].set_axis_off()\n",
        "ax[2].set_axis_off()\n",
        "\n",
        "# show figure\n",
        "plt.show()\n",
        "\n",
        "#for online google colab download\n",
        "#from google.colab import files\n",
        "\n",
        "#test = plt.figure()\n",
        "#plt.plot([1, 2, 3])\n",
        "#plt.savefig('test.pdf')\n",
        "\n",
        "#files.download('test.pdf')"
      ],
      "metadata": {
        "id": "VRbUABimohqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download new CSV data\n",
        "# for online google colab download\n",
        "from google.colab import files\n",
        "crime_census.to_csv('crime_census_export.csv', sep=',', index=False, encoding='utf-8')\n",
        "files.download('crime_census_export.csv')"
      ],
      "metadata": {
        "id": "HyX6lrWz7Phe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "Aptech. 2024. Color Brewer Palettes. [Online]. [Accessed 28 April 2024]. Available from: https://www.aptech.com/releases/gauss18/graphics-updates/color-brewer-palettes/\n",
        "\n",
        "Tableau. 2024. 5 tips on designing colour-blind friendly visualisation. [Online]. [Accessed 26 April 2024]. Available from: https://www.tableau.com/en-gb/blog/examining-data-viz-rules-dont-use-red-green-together\n",
        "\n",
        "Data Ninjas. 2021. Create a shapefile form a .csv with Python, web map it and reproject it. [Online]. [Accessed 20 April 2024]. Available from: https://www.youtube.com/watch?v=RAn8Lx0qrks\n",
        "\n",
        "jeremysze. 2019. Network Distance. [Online]. [Accessed 29 April 2024]. Available from: https://jeremysze.github.io/GIS_exploration/build/html/networkdistance_osm.html\n",
        "\n",
        "automating-gis-processes. 2017. Network analysis in Python. [Online]. [Accessed 29 April 2024]. Available from: https://automating-gis-processes.github.io/2017/lessons/L7/network-analysis.html\n",
        "\n",
        "Aric A. Hagberg, Daniel A. Schult and Pieter J. Swart, “Exploring network structure, dynamics, and function using NetworkX”, in Proceedings of the 7th Python in Science Conference (SciPy2008), Gäel Varoquaux, Travis Vaught, and Jarrod Millman (Eds), (Pasadena, CA USA), pp. 11–15, Aug 2008\n",
        "\n",
        "do-me. 2023. As of v0.10.0 geopandas supports sjoin_nearest natively. 13 October 2023. Finding nearest point in other GeoDataFrame using GeoPandas. [Online]. [Accessed 26 April 2024]. Available from: https://gis.stackexchange.com/questions/222315/finding-nearest-point-in-other-geodataframe-using-geopandas\n",
        "\n",
        "nomis. 2021. TS006 Population Density. Office for National Statistics. [Online]. [Accessed 7 April 2024]. Available from: https://www.nomisweb.co.uk/sources/census_2021_bulk\n",
        "\n",
        "nomis. 2021. TS0017 Household Size. Office for National Statistics. [Online]. [Accessed 7 April 2024]. Available from: https://www.nomisweb.co.uk/sources/census_2021_bulk\n",
        "\n",
        "nomis. 2021. TS050 Number of Bedrooms. Office for National Statistics. [Online]. [Accessed 7 April 2024]. Available from: https://www.nomisweb.co.uk/sources/census_2021_bulk\n",
        "\n",
        "Geoportal Statistics. 2023. Output Areas (December 2021) Boundaries EW BGC V2. ONS Geography. [Online]. [Accessed 7 April 2024]. Available from: https://geoportal.statistics.gov.uk/datasets/6beafcfd9b9c4c9993a06b6b199d7e6d_0/explore?location=53.594232%2C-1.209805%2C9.00\n",
        "\n",
        "data.police. no date. Data Download. data.police. [Online]. [Accessed 9 April 2024]. Available from: https://data.police.uk/data/\n",
        "\n",
        "digimap. 2023. Highways – Roads (GB). Digimap Edina. [Online]. [Accessed 9 April 2024]. Available from: https://digimap.edina.ac.uk/roam/map/os\n",
        "\n"
      ],
      "metadata": {
        "id": "iGaKpMN1HTe1"
      }
    }
  ]
}